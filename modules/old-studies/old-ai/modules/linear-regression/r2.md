# Coeficiente de Determinação R<sup>2</sup>

## Conteúdo

 - [01 - Soma dos Quadrados Totais (SQ<sub>t</sub>) / Total Sum of Squares (TSS)](#01)
 - [02 -  Soma dos Quadrados dos Resíduos (SQ<sub>res</sub>) / Residual Sum of Squares (RSS)](#02)
 - [03 - Coeficiente de determinação R<sup>2</sup>](#03)
 - [04 - Interpretando o Coeficiente de determinação R<sup>2</sup>](#04)
 - [05 - R<sup>2</sup> com Scikit-Learn na prática](#05)
 - [06 - Usando os conceitos de Regressão Linear + R<sup>2</sup> em um conjunto de dados reais](#06)
   - [06.1 - O argumento "random_state" do método train_test_split()](#06-1)

---

<div id='01'></div>

## 01 - Soma dos Quadrados Totais (SQ<sub>t</sub>) / Total Sum of Squares (TSS)

Bem, antes de pegar o **Coeficiente de Determinação R<sup>2</sup>** você sabe que *bixo* é esse? Não? Ok, vamos para uma breve explicação...

Suponha que nós criamos um gráfico com alguns dados para ver a relação entre preços de uma casa e seus tamanhos, ficou algo parecido com isso **(e não muito bonito)**:

![image](images/house-01.png)  

Se você prestar atenção vai ver que o nosso gráfico tem uma variação crescente, ou seja:

> A medida que aumenta o preço o tamanho também aumenta - vice e versa.

Agora suponha que eu quero criar um modelo que use uma reta para representar esses dados, de maneira que se eu inserir um novo preço ele tente descobrir (prever) qual o tamanho da casa.

**NOTE:**  
A primeira ideia que nós vamos ter é calcular a média dos tamanhos e traçar uma reta. Suponha que a reta ficou assim:

![image](images/house-02.png)  

Bem, essa reta não representa muito bem esse modelo. Se você prestar atenção vai ver que temos bastante erro. Como nós poderíamos calcular o erro desse módelo?

 - **1º -** É só pegar cada um dos valores (pontos no gráfico);
 - **2º -** Calcular a distância para a minha reta:
   - Cada ponto você vai elevar ao quadrado;
   - E depois somar com o próximo ponto.

No gráfico as distâncias dos pontos para a reta você pode ver assim:

![image](images/house-03.png)  

> Isso é o que nós conhecemos como **Soma dos Quadrados Totais - SQ<sub>t</sub>**

![img](images/TSS.png)  

**NOTE:**  
Na verdade o que nós fizemos acima foi tirar a *variância* dos nossos dados.

---

<div id="02"></div>

## 02 -  Soma dos Quadrados dos Resíduos (SQ<sub>res</sub>) / Residual Sum of Squares (RSS)

Continuando... Agora suponha que eu criei um novo modelo, porém com uma reta que parece se alinhar melhor com esses dados, veja abaixo:

![image](images/house-04.png)  

Ok, só de olhar já da para ver que essa reta representa bem melhor esses dados do que apenas tirar a média dos erros de todos os dados.

> A final ela parece está crescendo a mesma taxa que esses dados estão crescendo.

Mas, como eu posso provar que realmente essa segunda reta está melhor do que a outra? Ué, é só calcular cada uma dessas distâncias entre nossos dados e a reta verde (nova reta):

![image](images/house-05.png)  

> Isso é o que nós conhecemos como **Soma dos Quadrados dos Resíduos - SQ<sub>res</sub>**

![image](images/RSS.png)  

Ok, se nós calcularmos os dados nós vamos ver que o meu **SQ<sub>res</sub>** é menor do que o **SQ<sub>t</sub>**. Ou seja, o meu **SQ<sub>res</sub>** está melhor ajustado.

**NOTE:**  
Mas como eu sei quão melhor está o meu SQ<sub>res</sub> em relação ao SQ<sub>t</sub>? - **Ou seja, quão melhor ele está em relação a média**?

---

<div id="03"></div>

## 03 - Coeficiente de determinação R<sup>2</sup>

Então, é ai que entra o nosso querido **R<sup>2</sup>**... O R<sup>2</sup> nada mais é do que o meu SQ<sub>t</sub> menos SQ<sub>res</sub> dividido pelo SQ<sub>t</sub>:

![image](images/r2.png)  

Mas o que essa fórmula realmente significa na prática?

 - **Númerador:** Bem, no numerador nós vemos quão bem o meu modelo **SQ<sub>res</sub>** é em relação ao **SQ<sub>t</sub>**;
- **Denominador:** Quando nós dividimos pelo **SQ<sub>t</sub>** nós estamos `normalizando`, ou seja, nós estamos trazendo esse valor para uma escala que vale entre *zero* e *um*.

**Mas por que normalizar entre *zero* e *um*?**  
Ok, vamos ver... Suponha que nós criamos um modelo de Machine Learning muito ruim que criou uma reta que foi igual a soma dos quadrados totais **SQ<sub>t</sub>**, mais ou menos isso:

![image](images/house-06.png)  

Ué, o meu **SQ<sub>res</sub>** vai ser igual ao meu **SQ<sub>t</sub>**, logo, o meu **R<sup>2</sup>** vai ser **zero (0)**:

![image](images/r2-01.png)  

Agora vamos imaginar outro cenário (é só exemplo) onde os meus dados estão distribuídos de uma forma onde meu modelo de Machine Learning passe exatamente por todos os dados, ou seja, **não teve nenhum erro**:

![image](images/house-07.png)  

Então, como o nosso **SQ<sub>res</sub>** não teve nenhum erro, qual vai ser nosso **R<sup>2</sup>** agora?

![image](images/r2-02.png)  

Ótimo, mas o que o nosso **R<sup>2</sup>** nos diz?

 - Quanto **maior (mais perto de 1) o R<sup>2</sup> melhor** vai ser o meu cenário;
 - Quanto **menor (mais perto de 0) o R<sup>2</sup> pior** vai ser o meu ceunário.

---

<div id="04"></div>

## 04 - Interpretando o Coeficiente de determinação R<sup>2</sup>

Mas como nós poderíamos interpretar o nosso **R<sup>2</sup>**?

Por exemplo:

> Eu criei um modelo de Machine Learning que gerou o **R<sup>2</sup>** de 0,87.

O que isso significa?

> Significa que o meu modelo de Machine Learning é 87% melhor do que simplesmente pegar a média dos valores.

Outra abordagem de interpretação é dizer que o meu modelo explica **87% da variância dos dados**. Como assim?

 - Lembre que o cálculo do **SQ<sub>t</sub>** é o cálculo da *variância* do nosso conjunto de dados:
   - Ou seja, o resultado total da variância.
 - Enquanto o meu **SQ<sub>res</sub>** mostra quanto desta *variância* foi explicada:
   - Se o meu **R<sup>2</sup>** fosse 1 significaria que 100% da *variância* teria sido explicada - **zero erro na reta**.

---

<div id="05"></div>

## 05 - R<sup>2</sup> com Scikit-Learn na prática

Ta, mas como eu programo essa bruxaria toda ai? Simples, veja o código abaixo:

[r-squared.py](src/r-squared.py)  
```python
"""
R-Squared or Coefficient of Determination
"""

def createRegression(samples,variavel_numbers, n_noise):
  from sklearn.datasets import make_regression
  x, y = make_regression(n_samples=samples, n_features=variavel_numbers, noise=n_noise)
  return x, y

if __name__ =='__main__':

  from sklearn.linear_model import LinearRegression
  from sklearn.model_selection import train_test_split
  from matplotlib import pyplot as plt

  reg = createRegression(200, 1, 30)
  model = LinearRegression()

  x_train, x_test, y_train, y_test = train_test_split(reg[0], reg[1], test_size=0.30)
  model.fit(x_train, y_train)

  # Coefficient of Determination: R^2 / R-Squared.
  r2 = model.score(x_test, y_test)
  print('Coefficient of Determination: R^2: {0}'.format(r2))
```

**OUTPUT:**  
```python
Coefficient of Determination: R^2: 0.9158177316382643
```

Ótimo, pegamos o nosso **R<sup>2</sup>** que foi **0.91** ou seja, `nós explicamos 91% do nosso conjunto de dados`. Agora vamos ver qual foi a parte do código que fez isso e qual foi a lógica:

Primeiro nós criamos um modelo com os **dados de treino**:

```python
model.fit(x_train, y_train)
```

E depois apenas com os **dados de teste** nós pegamos o **R<sup>2</sup>** com o método **score()**:

```python
# Coefficient of Determination: R^2 / R-Squared.
r2 = model.score(x_test, y_test)
```

---

<div id="06"></div>

## 06 - Usando os conceitos de Regressão Linear + R<sup>2</sup> em um conjunto de dados reais

Ótimo, partindo do pressuposto que vocês já sabem como funciona uma **[Regressão Linear](linear-regression-sse-ols-gd.md)** e agora como funciona o **Coeficiente de Determinação R<sup>2</sup>**, vamos ver como funciona isso em um conjunto de dados reais.

Para isso vamos trabalhar com o Dataset do município **King County** localizado no estado de Washington nos Estados Unidos da América (USA). Esse Dataset pode ser baixado facilmente dando uma `Googlada` ou você pode vir aqui no [Kaggle](https://www.kaggle.com/harlfoxem/housesalesprediction).

Basicamente esse Dataset tem dados das casas vendidas no município de **King County**. Esses dados são formados por 21 colunas, que são:

 - **id -** ID da casa;
 - **date -** Data em que a casa foi vendida;
 - **price -** `Preço é meta da previsão;`
 - **bedrooms -** Número de quartos casa;
 - **bathrooms -** Número de banheiros da casa;
 - **sqft_living -** Metragem quadrada da casa
 - **sqft_lot -** Metragem quadrada do lote;
 - **floors -** Pisos totais (níveis) em casa;
 - **waterfront -** Casa com vista para a água (mar/lagoa);
 - **view -** Foi visualizado;
 - **condition -** Quão boa é a condição (geral);
 - **grade -** Nota geral dada à unidade habitacional, com base no sistema de classificação de King County;
 - **sqft_above -** Metragem quadrada de casa além do porão;
 - **sqft_basement -** Metragem quadrada do porão;
 - **yr_built -** Ano de construção;
 - **yr_renovated -** Ano em que a casa foi reformada;
 - **zipcode -** Código postal (CEP no Brasil);
 - **lat -** Coordenada de latitude;
 - **long -** Coordenada de longitude;
 - **sqft_living15 -** Área da sala de estar em 2015 (implica-- algumas reformas) Isso pode ou não ter afetado a área de tamanho grande;
 - **sqft_lot15 -**  Área lotSize em 2015 (implica-- algumas reformas).

**NOTE:**  
Até então nós estavamos trabalhando apenas com duas variáveis, onde tinhamos o meu ponto **x** e o seu correspondente **y** e ficava muito fácil criar uma *Regressão Linear* em um plano **bidimensional**.  

Só lembrando a fórmula de **Regressão Linear** era essa:

![image](images/linear-regression-formule.png)  

Agora nós temos que aplicar essa fórmula no nosso Dataset **King County**, porém, ele tem `várias variáveis`. Como isso se aplica na prática?

**RESPOSTA:**  
Então, a lógica vai ser a mesma... Porém, ao invés de **y = mx + b** nós vamos ter:

![image](images/new-lr.png)  

Onde,

 - Cada variável vai ser representada por **x<sub>n</sub>** no seu respectivo índice - **(x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>, ... x<sub>n</sub>)**;
 - Cada variável **x<sub>n</sub>** vai ter seu próprio Coeficiente Angular **m<sub>n</sub>**:
   - Esses Coeficientes Angulares **m<sub>n</sub>** que multiplicam as variáveis podem ser vistos como pesos *(weight)* de acordo com a variável.
 - Por fim, nós vamos ter apenas um Coeficiente Linear **(b)**.

Ótimo, entendido! Mas como aplicar isso em Python e Scikit-Learn e pegar o nosso Coeficiente de Determinação **R<sup>2</sup>**?

[houses_predict.py](src/houses_predict.py)  
```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from matplotlib import pyplot as plt
import pandas as pd

pd.set_option('display.max_columns', 21)
df = pd.read_csv('../datasets/kc_house_data.csv')
df = df.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis=1)

y = df['price']
x = df.drop(['price'], axis=1)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

model = LinearRegression()
model.fit(x_train, y_train)

r2 = model.score(x_test, y_test)
print('Coefficient of Determination: R^2: {0}'.format(r2))
```

**OUTPUT:**  
```python
Coefficient of Determination: R^2: 0.6517197736446649
```

Ou seja,

 - Significa que o meu modelo de Machine Learning é **65% melhor do que simplesmente pegar a média dos valores**;
 - Ou, o meu modelo explica **65% da variância dos dados**.

**NOTE:**  
Outra observação é que talvez o seu resultado seja diferente. Isso porque o método **train_test_split()** separa os dados de treino e testes aleatoriamente.

Isso pode ser ruim em alguns casos, por exemplo, nós estamos ajustando os pesos (**m<sub>n</sub>**) das variáveis para encontrar um **R<sup>2</sup>** melhor para o nosso modelo. Como resolver isso?

<div id="06-1"></div>

## 06.1 - O argumento "random_state" do método train_test_split()

O método **train_test_split()** também pode receber um argumento chamado **random_state**. Com ele basicamente nós passamos um inteiro e é feito um embaralhamento dos dados, onde, sempre que você ou qualquer pessoa executar o método **train_test_split()** **no mesmo conjunto de dados**, os dados de treino e testes serão os mesmo se ambos tiverem o mesmo argumento **random_state**.

Veja abaixo como fica:

[houses_predict_w_random_state.py](src/houses_predict_w_random_state.py)
```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from matplotlib import pyplot as plt
import pandas as pd

pd.set_option('display.max_columns', 21)
df = pd.read_csv('../datasets/kc_house_data.csv')
df = df.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis=1)

y = df['price']
x = df.drop(['price'], axis=1)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=10)

model = LinearRegression()
model.fit(x_train, y_train)

r2 = model.score(x_test, y_test)
print('Coefficient of Determination: R^2: {0}'.format(r2))
```

**OUTPUT:**  
```python
Coeficiente de Determinação R^2: 0.6608668622831475
```

**NOTE:**  
Agora se você ou qualquer outra pessoa executar a mesma amostra de dados com o **random_state=10** os dados de treino e testes vão ser sempre o mesmo.

> Ou seja, o Coeficiente de Determinação R<sup>2</sup> vai ser sempre o mesmo.

---

**REFERENCES:**  
[Didatica Tech - MÓDULO - I](https://didatica.tech/)  
